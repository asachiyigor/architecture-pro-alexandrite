---
up:
  - "[[Task2]]"
---
# Выбор и настройка мониторинга в системе

## Мотивация

### Зачем нужен мониторинг

Компания "Александрит" столкнулась с серьезными проблемами в работе IT-систем, которые напрямую влияют на бизнес:

1. **Потеря заказов и выручки**
   - Клиенты и партнеры жалуются на неполученные заказы
   - Компания уже потеряла несколько крупных B2B контрактов
   - Растет недовольство B2C клиентов

2. **Отсутствие видимости проблем**
   - Невозможно быстро определить, где "застревают" заказы
   - Нет понимания, какие компоненты системы перегружены
   - Проблемы обнаруживаются только после жалоб пользователей

3. **Невозможность масштабирования**
   - Нагрузка растет линейно (+100 заказов/месяц)
   - После открытия API нагрузка возросла многократно
   - Нет данных для принятия решений о масштабировании

4. **Долгое устранение инцидентов**
   - Отсутствие инструментов для быстрой диагностики
   - Команда узнает о проблемах последней (после пользователей)
   - Нет исторических данных для анализа инцидентов

### Что даст компании внедрение мониторинга

#### Бизнес-выгоды

1. **Сокращение потерь от простоев**
   - Раннее обнаружение проблем до влияния на клиентов
   - Сокращение времени простоя с часов до минут
   - Предотвращение потери крупных контрактов

2. **Улучшение качества обслуживания клиентов**
   - Проактив ное решение проблем
   - Повышение удовлетворенности клиентов (NPS)
   - Снижение количества жалоб на 80-90%

3. **Возможность роста и масштабирования**
   - Данные для планирования мощностей
   - Обоснование инвестиций в инфраструктуру
   - Поддержка растущей нагрузки без деградации сервиса

4. **Экономия ресурсов**
   - Оптимизация использования серверов (right-sizing)
   - Снижение затрат на поддержку за счет автоматизации
   - Предотвращение дорогостоящих инцидентов

#### Технические преимущества

1. **Видимость работы системы в реальном времени**
   - Дашборды с ключевыми метриками
   - Понимание узких мест и bottlenecks
   - Отслеживание SLA и SLO

2. **Быстрая диагностика проблем**
   - Сокращение MTTR (Mean Time To Repair) с часов до минут
   - Корреляция метрик для выявления причин
   - Исторические данные для анализа трендов

3. **Проактивное выявление проблем**
   - Алертинг до влияния на пользователей
   - Предсказание проблем по трендам
   - Автоматическое оповещение команды

4. **Основа для автоматизации**
   - Auto-scaling на основе метрик
   - Self-healing систем
   - Автоматические действия при алертах

#### Метрики успеха внедрения мониторинга

- **MTTR (Mean Time To Repair)**: снижени   е с 4-6 часов до 15-30 минут
- **MTTD (Mean Time To Detect)**: снижение с 2-3 часов до 1-5 минут
- **Процент инцидентов, обнаруженных до пользователей**: увеличение с 0% до 80%+
- **Количество потерянных заказов**: снижение до 0
- **Uptime приложений**: увеличение до 99.9%+
- **Удовлетворенность клиентов (NPS)**: рост на 20-30 пунктов

---

## Выбор подхода к мониторингу

Для компании "Александрит" предлагается использовать комбинированный подход, сочетающий методологии **RED** и **USE**.

### RED-метод для сервисов и API

**RED (Rate, Errors, Duration)** будет применяться для мониторинга всех сервисов и API:

- **Интернет-магазин API**
- **CRM API**
- **MES API**
- **Публичный API для партнеров**

**Обоснование выбора:**
- Система ориентирована на обработку запросов (request-driven)
- Важна скорость ответа для пользователей
- Критичен процент ошибок (влияет на потерю заказов)
- Позволяет отслеживать пропускную способность (capacity planning)

**Метрики RED:**
1. **Rate (частота запросов)** - RPS (Requests Per Second)
2. **Errors (ошибки)** - процент и количество ошибочных запросов
3. **Duration (длительность)** - время ответа (latency)

### USE-метод для инфраструктуры

**USE (Utilization, Saturation, Errors)** будет применяться для мониторинга инфраструктурных ресурсов:

- **Серверы** (EC2 инстансы)
- **Базы данных** (PostgreSQL для Shop и MES)
- **Очереди** (RabbitMQ)
- **Хранилище** (S3, диски)

**Обоснование выбора:**
- Нужно отслеживать использование физических ресурсов
- Важно выявлять насыщенность (saturation) до деградации сервиса
- Критично для планирования масштабирования

**Метрики USE:**
1. **Utilization (утилизация)** - % использования ресурса
2. **Saturation (насыщенность)** - очереди ожидания, задержки
3. **Errors (ошибки)** - ошибки на уровне инфраструктуры

### Почему не «Четыре золотых сигнала»

Методология «Четырех золотых сигналов» от Google SRE частично пересекается с RED, но включает дополнительный компонент - Saturation. В нашем случае:

- **Saturation** будет отслеживаться через USE-метод для инфраструктуры
- RED дает более фокусированный подход для микросервисов
- Комбинация RED + USE покрывает все аспекты четырех золотых сигналов

---

## Метрики для отслеживания

### Критерии выбора метрик

1. **Релевантность** - метрика должна помогать выявлять и решать реальные проблемы
2. **Действенность (Actionable)** - по метрике можно принять конкретное решение
3. **Стоимость сбора** - баланс между ценностью и затратами на сбор
4. **Понятность** - метрика должна быть понятна команде

### Выбранные метрики

#### 1. Number of dead-letter-exchange letters in RabbitMQ ✅

**Назначение:**
- Отслеживание потерянных сообщений в очередях
- Выявление проблем в обработке заказов между MES и CRM

**Зачем нужна:**
Это критическая метрика для компании "Александрит", так как потеря сообщений напрямую приводит к потере заказов. DLQ (Dead Letter Queue) накапливает сообщения, которые не удалось обработать.

**Ярлыки (Labels):**
- `queue_name`: имя очереди (orders, calculations, notifications)
- `reason`: причина попадания в DLQ (rejected, expired, max-retries)
- `source_service`: сервис-отправитель (shop, crm, mes)

**Пороговые значения:**
- **Warning**: > 0 сообщений в DLQ
- **Critical**: > 10 сообщений или рост более 5/минуту

**Действия при превышении:**
- Алерт команде разработки
- Автоматическое логирование деталей сообщений
- Расследование причин и retry вручную при необходимости

---

#### 2. Number of messages in flight in RabbitMQ ✅

**Назначение:**
- Мониторинг количества необработанных сообщений в очереди
- Выявление проблем с производительностью consumer'ов

**Зачем нужна:**
Большое количество сообщений "в полете" указывает на то, что consumers не успевают обрабатывать нагрузку. Это может привести к задержкам в обработке заказов.

**Ярлыки:**
- `queue_name`: имя очереди
- `consumer_service`: сервис-обработчик

**Пороговые значения:**
- **Warning**: > 100 сообщений
- **Critical**: > 500 сообщений или постоянный рост

**Действия при превышении:**
- Проверить health consumers
- Масштабировать количество workers
- Исследовать причину медленной обработки

---

#### 3. Number of requests (RPS) for internet shop API ✅ (RED - Rate)

**Назначение:**
- Отслеживание трафика интернет-магазина
- Capacity planning и масштабирование

**Зачем нужна:**
Основная метрика для понимания нагрузки на систему. Рост RPS требует масштабирования инфраструктуры.

**Ярлыки:**
- `endpoint`: путь API (/products, /cart, /orders)
- `http_method`: HTTP метод (GET, POST)
- `status_code_group`: группа кодов ответа (2xx, 4xx, 5xx)

**Пороговые значения:**
- **Baseline**: текущая средняя нагрузка
- **Warning**: рост на 50% от baseline
- **Critical**: приближение к максимальной пропускной способности (определяется нагрузочным тестированием)

---

#### 4. Number of requests (RPS) for CRM API ✅ (RED - Rate)

**Назначение:**
- Отслеживание использования CRM менеджерами
- Выявление пиковых нагрузок

**Ярлыки:**
- `endpoint`: функциональность CRM
- `user_role`: роль пользователя (manager, admin)

---

#### 5. Number of requests (RPS) for MES API ✅ (RED - Rate)

**Назначение:**
- Отслеживание использования MES операторами
- Важная метрика для производственных процессов

**Ярлыки:**
- `endpoint`: операции MES (/orders/list, /order/:id/status)
- `operation_type`: тип операции (read, write)

---

#### 6. Number of requests (RPS) per user for internet shop API ✅

**Назначение:**
- Выявление аномальной активности
- Защита от DDoS и злоупотреблений

**Зачем нужна:**
Позволяет выявить:
- Потенциальные DDoS атаки
- Ботов и скраперов
- Аномальное поведение пользователей

**Ярлыки:**
- `user_id_hash`: хеш идентификатора пользователя
- `endpoint_group`: группа эндпоинтов

**Пороговые значения:**
- **Warning**: > 100 RPS от одного пользователя
- **Critical**: > 500 RPS (возможная атака)

**Действия:**
- Автоматический rate limiting
- Блокировка при превышении порогов
- Логирование для расследования

---

#### 9-11. CPU % for shop/CRM/MES API ✅ (USE - Utilization)

**Назначение:**
- Мониторинг загрузки процессора каждого сервиса
- Выявление ресурсозатратных операций

**Зачем нужна:**
Высокая загрузка CPU указывает на:
- Необходимость оптимизации кода
- Потребность в масштабировании
- Возможные проблемы (infinite loops, неэффективные алгоритмы)

**Ярлыки:**
- `instance_id`: идентификатор инстанса
- `service_name`: имя сервиса

**Пороговые значения:**
- **Warning**: > 70% в течение 5 минут
- **Critical**: > 85% в течение 5 минут или > 90% в течение 1 минуты

**Действия:**
- Проверить наличие медленных запросов
- Рассмотреть горизонтальное масштабирование
- Профилирование приложения

---

#### 12-14. Memory Utilization for shop/CRM/MES API ✅ (USE - Utilization)

**Назначение:**
- Отслеживание использования памяти приложениями
- Выявление утечек памяти (memory leaks)

**Зачем нужна:**
- Предотвращение OOM (Out Of Memory) ошибок
- Выявление утечек памяти
- Оптимизация использования ресурсов

**Ярлыки:**
- `instance_id`: идентификатор инстанса
- `memory_type`: тип памяти (heap, non-heap для JVM)

**Пороговые значения:**
- **Warning**: > 80%
- **Critical**: > 90% или постоянный рост (утечка памяти)

**Действия:**
- Проверка на memory leaks
- Перезапуск сервиса при необходимости
- Heap dump для анализа

---

#### 15-16. Memory Utilization for shop/MES db instance ✅ (USE - Utilization)

**Назначение:**
- Мониторинг памяти баз данных
- Оптимизация buffer pool и кешей

**Зачем нужна:**
БД интенсивно использует память для кеширования. Недостаток памяти приводит к падению производительности.

**Ярлыки:**
- `db_name`: имя базы данных
- `instance_id`: инстанс БД

**Пороговые значения:**
- **Warning**: > 85%
- **Critical**: > 95%

**Действия:**
- Оптимизация настроек БД (buffer pool size)
- Масштабирование инстанса БД
- Анализ медленных запросов

---

#### 17-18. Number of connections for shop/MES db instance ✅ (USE - Saturation)

**Назначение:**
- Отслеживание количества активных подключений к БД
- Выявление проблем с connection pooling

**Зачем нужна:**
Исчерпание пула соединений приводит к ошибкам "cannot connect to database" и деградации сервиса.

**Ярлыки:**
- `connection_state`: состояние подключения (active, idle)
- `application`: приложение-источник подключений

**Пороговые значения:**
- **Warning**: > 70% от max_connections
- **Critical**: > 90% от max_connections

**Действия:**
- Проверка connection leaks в приложении
- Оптимизация connection pool settings
- Увеличение max_connections (временно)

---

#### 19-21. Response time (latency) for shop/CRM/MES API ✅ (RED - Duration)

**Назначение:**
- Мониторинг времени ответа API
- Отслеживание пользовательского опыта

**Зачем нужна:**
Время ответа напрямую влияет на удовлетворенность пользователей. Критическая метрика для SLA.

**Ярлыки:**
- `endpoint`: конкретный эндпоинт
- `percentile`: процентиль (p50, p95, p99)

**Пороговые значения (p95):**
- **Shop API**:
  - Warning: > 500ms
  - Critical: > 1000ms
- **CRM API**:
  - Warning: > 300ms
  - Critical: > 800ms
- **MES API**:
  - Warning: > 500ms
  - Critical: > 1200ms (учитывая дашборд с большим количеством данных)

**Действия:**
- Анализ медленных запросов
- Проверка кеша
- Оптимизация SQL-запросов
- Проверка нагрузки на БД

---

#### 22. Size of S3 storage ✅

**Назначение:**
- Мониторинг размера хранилища 3D-моделей
- Прогнозирование затрат на S3

**Зачем нужна:**
- Cost management (оплата за хранение)
- Планирование архивации старых файлов
- Выявление аномального роста (возможно, загружаются неоптимизированные файлы)

**Ярлыки:**
- `bucket_name`: имя S3 bucket
- `file_type`: тип файлов (3d_models, images)

**Пороговые значения:**
- Отслеживание тренда роста
- Алерт при неожиданном резком росте (> 20% в день)

---

#### 23-24. Size of shop/MES db instance ✅

**Назначение:**
- Мониторинг роста баз данных
- Планирование расширения дискового пространства

**Зачем нужна:**
- Предотвращение исчерпания дискового пространства
- Планирование очистки или архивации данных
- Оценка необходимости партиционирования таблиц

**Ярлыки:**
- `db_name`: имя базы данных
- `table_name`: имя таблицы (для детализации)

**Пороговые значения:**
- **Warning**: > 70% от доступного пространства
- **Critical**: > 85%

---

#### 28-30. Number of HTTP 500 for shop/CRM/MES API ✅ (RED - Errors)

**Назначение:**
- Отслеживание серверных ошибок
- Мониторинг стабильности сервисов

**Зачем нужна:**
HTTP 500 ошибки указывают на проблемы в работе приложения. Критично для надежности сервиса.

**Ярлыки:**
- `endpoint`: проблемный эндпоинт
- `error_type`: тип ошибки (database_error, timeout, internal_error)

**Пороговые значения:**
- **Warning**: > 0.5% от общего количества запросов
- **Critical**: > 2% или > 10 ошибок/минуту

**Действия:**
- Немедленное расследование
- Проверка логов и трейсинга
- Откат на предыдущую версию при необходимости

---

### Метрики, которые НЕ выбраны и почему

#### HTTP 200 responses (25-27)
**Почему не выбрана:**
- Избыточна при наличии метрик RPS и ошибок
- Можно вычислить: успешные запросы = RPS - ошибки

#### Requests per user для CRM/MES (7-8)
**Почему не выбрана:**
- CRM и MES - внутренние системы с авторизованными пользователями
- Риск злоупотреблений минимален
- Ограниченное количество пользователей (операторы, менеджеры)
- Можно добавить позже при необходимости

#### Simultaneous sessions (32-34)
**Почему не выбрана:**
- Косвенная метрика, не дает actionable инсайтов
- Лучше фокусироваться на RPS и memory utilization

#### Kb transferred/received (35-40)
**Почему не выбрана на начальном этапе:**
- Полезна для оптимизации, но не критична сейчас
- Можно добавить на следующем этапе мониторинга
- Более важные метрики - latency и error rate

---

## План действий

### Этап 1: Подготовка инфраструктуры (Недели 1-2)

#### 1.1 Развертывание Prometheus
- **Задача:** Установить Prometheus сервер в отдельном EC2 инстансе
- **Конфигурация:**
  - Retention: 30 дней для метрик
  - Scrape interval: 15 секунд
  - Создать отдельные job'ы для каждого сервиса
- **Ответственный:** DevOps инженер

#### 1.2 Настройка хранилища метрик
- **Задача:** Настроить persistent storage для Prometheus
- **Детали:**
  - EBS volume с автоматическими snapshot'ами
  - Планирование capacity: ~500GB для начала
- **Ответственный:** DevOps инженер

#### 1.3 Развертывание Grafana
- **Задача:** Установить Grafana для визуализации
- **Конфигурация:**
  - Интеграция с Prometheus как data source
  - Настройка пользователей и ролей
  - Настройка SMTP для email алертов
- **Ответственный:** DevOps инженер

### Этап 2: Инструментация приложений (Недели 2-4)

#### 2.1 Установка exporters
- **Java приложения (Shop, CRM):**
  - Подключить Prometheus JMX exporter
  - Добавить Micrometer для application-level метрик
  - Конфигурация: `/actuator/prometheus` endpoint

- **C# приложение (MES):**
  - Установить prometheus-net библиотеку
  - Создать `/metrics` endpoint
  - Экспорт custom метрик

- **RabbitMQ:**
  - Включить prometheus plugin
  - Endpoint: `:15692/metrics`

- **PostgreSQL:**
  - Установить postgres_exporter
  - Мониторинг обеих БД (Shop и MES)

**Ответственные:** Backend разработчики

#### 2.2 Добавление custom метрик
- **Бизнес-метрики:**
  - Количество созданных заказов
  - Количество расчетов стоимости
  - Время расчета стоимости
  - Статусы заказов

**Ответственные:** Backend разработчики

### Этап 3: Создание дашбордов (Неделя 5)

#### 3.1 RED дашборды для сервисов
Создать дашборды в Grafana для каждого сервиса:

**Shop API Dashboard:**
- Panel 1: RPS по эндпоинтам (Rate)
- Panel 2: Error rate % (Errors)
- Panel 3: Response time p50/p95/p99 (Duration)
- Panel 4: Топ медленных эндпоинтов

**CRM API Dashboard:**
- Аналогичная структура

**MES API Dashboard:**
- Аналогичная структура
- Дополнительно: метрики расчета стоимости

#### 3.2 USE дашборды для инфраструктуры

**Infrastructure Overview Dashboard:**
- CPU utilization всех инстансов
- Memory utilization
- Disk usage
- Network I/O

**Database Dashboard:**
- Connections count
- Query performance
- Slow queries count
- Database size growth

**RabbitMQ Dashboard:**
- Messages in-flight по очередям
- Dead letter queue size
- Consumer lag
- Message rate (publish/consume)

#### 3.3 Business Metrics Dashboard
- Количество заказов по статусам
- Среднее время обработки заказа
- Конверсия в оформление заказа
- API usage по партнерам

**Ответственные:** DevOps + Product Manager (определение метрик)

### Этап 4: Настройка алертинга (Неделя 6)

#### 4.1 Критические алерты
1. **High Error Rate**
   - Условие: error rate > 2% в течение 5 минут
   - Канал: Email + Slack (critical channel)
   - On-call escalation: немедленно

2. **Service Down**
   - Условие: up == 0
   - Канал: Email + Slack + SMS
   - Действие: автоматический перезапуск (если доступен)

3. **Dead Letter Queue Growth**
   - Условие: DLQ size > 10 или рост > 5/мин
   - Канал: Email + Slack
   - Действие: проверка consumer health

4. **Database Connections Exhausted**
   - Условие: connections > 90% от max
   - Канал: Email + Slack (critical)
   - Действие: проверка connection leaks

5. **High Response Time**
   - Условие: p95 latency > критического значения в течение 5 минут
   - Канал: Slack
   - Действие: проверка медленных запросов

#### 4.2 Warning алерты
1. **High CPU Usage**
   - Условие: CPU > 70% в течение 10 минут
   - Канал: Slack

2. **High Memory Usage**
   - Условие: Memory > 80%
   - Канал: Slack

3. **Disk Space Low**
   - Условие: Disk > 70% full
   - Канал: Email

4. **RabbitMQ Consumer Lag**
   - Условие: in-flight > 100 messages
   - Канал: Slack

#### 4.3 Настройка каналов уведомлений
- **Slack:** Создать каналы #alerts-critical и #alerts-warning
- **Email:** Настроить группы рассылки (dev-team, ops-team)
- **PagerDuty** (опционально): Для on-call rotation

**Ответственные:** DevOps + Team Lead

### Этап 5: Документация и обучение (Неделя 7)

#### 5.1 Создание runbook'ов
Для каждого алерта создать runbook с описанием:
- Что означает алерт
- Возможные причины
- Шаги по диагностике
- Шаги по устранению

**Пример runbook для "High Error Rate":**
```
1. Проверить логи приложения на наличие stack traces
2. Проверить дашборд: какой эндпоинт дает ошибки
3. Проверить database dashboard: есть ли проблемы с БД
4. Проверить recent deployments: был ли недавний деплой
5. При необходимости: откат на предыдущую версию
```

#### 5.2 Обучение команды
- Провести воркшоп по Grafana (2 часа)
- Демо основных дашбордов
- Обучение работе с алертами
- Практика: симуляция инцидента

**Ответственные:** DevOps + Team Lead

### Этап 6: Continuous Improvement (Ongoing)

#### 6.1 Еженедельный review
- Анализ сработавших алертов
- Выявление false positives
- Корректировка порогов
- Добавление новых метрик при необходимости

#### 6.2 Monthly reporting
- Отчет о доступности сервисов (uptime)
- Тренды производительности
- Top issues по метрикам
- Recommendations для улучшений

**Ответственные:** Team Lead + DevOps

---

## Дополнительное задание: Показатели насыщенности (Saturation)

### Определение пороговых значений насыщенности

Насыщенность (Saturation) - это степень, до которой ресурс переполнен работой, которую не может выполнить, часто выражающаяся как очередь ожидания.

### 1. Database Connection Pool Saturation

**Ресурс:** Пул подключений к БД

**Метрика насыщенности:**
```
connection_pool_saturation = (active_connections / max_connections) * 100
```

**Пороговые значения:**
- **Green zone**: < 60% - нормальная работа
- **Yellow zone**: 60-80% - внимание, возможно потребуется масштабирование
- **Orange zone**: 80-90% - предупреждение, близко к насыщению
- **Red zone**: > 90% - критическая насыщенность

**Почему именно эти значения:**
- При > 90% высокий риск отказа в обслуживании новых запросов
- Запас 10-20% необходим для пиковых нагрузок
- Учитывается время создания нового подключения (100-300ms)

**Действия при превышении:**

**80-90% (Warning):**
- Алерт DevOps команде
- Анализ: проверить connection leaks в приложении
- Временное решение: увеличить connection pool size
- Долгосрочное: оптимизация запросов, добавление read replicas

**> 90% (Critical):**
- Срочный алерт + escalation
- Проверить и закрыть зависшие подключения
- Перезапуск приложения (если обнаружен leak)
- Экстренное масштабирование БД

### 2. RabbitMQ Queue Saturation

**Ресурс:** Очереди сообщений

**Метрика насыщенности:**
```
queue_saturation = messages_ready / queue_capacity_threshold
```

**Для очереди заказов (orders queue):**

**Пороговые значения:**
- **Green**: < 100 messages - нормально
- **Yellow**: 100-500 messages - consumers отстают
- **Orange**: 500-1000 messages - значительная задержка
- **Red**: > 1000 messages - критическое отставание

**Почему именно эти значения:**
- Среднее время обработки сообщения: 2-3 секунды
- При 100 сообщениях задержка: ~3-5 минут (приемлемо)
- При 1000 сообщениях задержка: ~30-50 минут (неприемлемо для бизнеса)
- Учитываются SLA по времени обработки заказа

**Действия при превышении:**

**100-500 messages (Warning):**
- Мониторинг роста очереди
- Проверить health consumer'ов
- Логирование: записать в лог для анализа тренда

**500-1000 messages (High Warning):**
- Алерт команде
- Масштабировать количество consumer instances
- Проверить причину медленной обработки
- Анализ: не замедлились ли downstream сервисы

**> 1000 messages (Critical):**
- Срочный алерт + escalation
- Немедленное масштабирование consumers (auto-scaling)
- Анализ bottleneck: БД, внешние API, алгоритм обработки
- Временное увеличение ресурсов consumer instances (CPU/Memory)
- Рассмотреть параллельную обработку (если безопасно для бизнес-логики)

### 3. CPU Queue (Run Queue) Saturation

**Ресурс:** CPU процессора

**Метрика насыщенности:**
```
cpu_saturation = cpu_run_queue_length / number_of_cpu_cores
```

**Пороговые значения:**
- **Green**: < 1.0 - CPU справляется
- **Yellow**: 1.0-2.0 - CPU начинает насыщаться
- **Orange**: 2.0-4.0 - высокая насыщенность
- **Red**: > 4.0 - критическая насыщенность

**Почему именно эти значения:**
- Run queue 1.0 на ядро означает, что есть процессы в ожидании
- > 2.0 значит процессы ждут в среднем 2x времени процессора
- При > 4.0 значительные задержки в обработке

**Действия при превышении:**

**1.0-2.0 (Warning):**
- Мониторинг тренда
- Проверить top процессы по CPU
- Запланировать анализ производительности

**2.0-4.0 (High Warning):**
- Алерт команде
- Профилирование приложения
- Поиск неэффективных операций
- Рассмотреть горизонтальное масштабирование

**> 4.0 (Critical):**
- Срочный алерт
- Немедленное масштабирование (добавление инстансов)
- Перезапуск проблемных процессов
- Экстренный анализ: возможно infinite loop или DDoS

### 4. Memory Saturation (Swap Usage)

**Ресурс:** Оперативная память

**Метрика насыщенности:**
```
memory_saturation = swap_used_mb / total_swap_mb * 100
```

**Пороговые значения:**
- **Green**: 0% swap - отлично
- **Yellow**: 1-10% swap - начинается swapping
- **Orange**: 10-50% swap - серьезная проблема
- **Red**: > 50% swap - критическая ситуация

**Почему именно эти значения:**
- Swap на несколько порядков медленнее RAM
- Даже небольшой swap (1-5%) может значительно замедлить приложение
- При > 50% swap система практически неработоспособна

**Действия при превышении:**

**1-10% (Warning):**
- Алерт DevOps
- Анализ: какие процессы используют много памяти
- Проверка на memory leaks
- Планирование увеличения RAM или масштабирования

**10-50% (High Warning):**
- Срочный алерт
- Анализ и kill процессов с memory leaks
- Перезапуск проблемного сервиса
- Временное увеличение инстанса (больше RAM)

**> 50% (Critical):**
- Критический алерт + escalation
- Экстренный перезапуск сервиса
- Переключение трафика на здоровые инстансы (если есть LB)
- Немедленное увеличение размера инстанса

### 5. Disk I/O Saturation

**Ресурс:** Диск

**Метрика насыщенности:**
```
disk_saturation = avg_disk_queue_length
```

**Пороговые значения:**
- **Green**: < 1.0 - диск не перегружен
- **Yellow**: 1.0-3.0 - начинается насыщение
- **Orange**: 3.0-5.0 - высокая насыщенность
- **Red**: > 5.0 - критическая насыщенность

**Почему именно эти значения:**
- Disk queue length > 1.0 означает наличие ожидающих операций
- SSD обычно справляется лучше, чем HDD
- При > 5.0 значительные задержки I/O операций

**Действия при превышении:**

**1.0-3.0 (Warning):**
- Мониторинг: какие процессы создают I/O
- Анализ: оптимизация запросов к БД
- Проверка: возможно нужны индексы

**3.0-5.0 (High Warning):**
- Алерт команде
- Проверка на лишнее логирование
- Оптимизация БД (vacuuming, indexing)
- Рассмотреть переход на быстрые диски (SSD → NVMe)

**> 5.0 (Critical):**
- Срочный алерт
- Экстренное расширение IOPS (для EBS)
- Миграция на более быстрое хранилище
- Временное снижение нагрузки (rate limiting)

### 6. HTTP Request Queue Saturation (Application Level)

**Ресурс:** Очередь HTTP-запросов в приложении

**Метрика насыщенности:**
```
http_queue_saturation = queued_requests / thread_pool_size
```

**Для Java приложений (Shop, CRM):**

**Пороговые значения:**
- **Green**: < 0.5 - очереди практически нет
- **Yellow**: 0.5-1.0 - начинается очередь
- **Orange**: 1.0-2.0 - запросы ждут обработки
- **Red**: > 2.0 - критическая очередь

**Почему именно эти значения:**
- При ratio > 1.0 на каждый обрабатываемый запрос есть минимум один ожидающий
- При > 2.0 высокая вероятность timeouts
- Учитывается среднее время обработки запроса

**Действия при превышении:**

**0.5-1.0 (Warning):**
- Мониторинг тренда
- Проверка: нет ли медленных запросов
- Анализ: возможно нужно кеширование

**1.0-2.0 (High Warning):**
- Алерт команде
- Увеличение размера thread pool (временно)
- Оптимизация медленных запросов
- Добавление кеширования
- Масштабирование приложения

**> 2.0 (Critical):**
- Срочный алерт + escalation
- Немедленное горизонтальное масштабирование
- Включение rate limiting (защита от перегрузки)
- Проверка на DDoS атаку
- Circuit breaker для downstream сервисов

---

## Итоговая таблица пороговых значений насыщенности

| Ресурс | Метрика | Green | Yellow | Orange | Red | Действие при Red |
|--------|---------|-------|--------|--------|-----|------------------|
| DB Connections | % от max | < 60% | 60-80% | 80-90% | > 90% | Срочное масштабирование БД, поиск leaks |
| RabbitMQ Queue | Messages ready | < 100 | 100-500 | 500-1K | > 1K | Auto-scale consumers, анализ bottleneck |
| CPU | Run queue/cores | < 1.0 | 1.0-2.0 | 2.0-4.0 | > 4.0 | Масштабирование, профилирование |
| Memory | Swap usage % | 0% | 1-10% | 10-50% | > 50% | Перезапуск, увеличение RAM |
| Disk I/O | Avg queue length | < 1.0 | 1.0-3.0 | 3.0-5.0 | > 5.0 | Faster disks, снижение нагрузки |
| HTTP Queue | Queued/threads | < 0.5 | 0.5-1.0 | 1.0-2.0 | > 2.0 | Масштабирование, rate limiting |

### Автоматизация реакции на насыщенность

**Уровень 1: Мониторинг**
- Все метрики насыщенности собираются каждые 15 секунд
- Дашборд в Grafana с color coding (green/yellow/orange/red)
- Отображение трендов за последние 24 часа

**Уровень 2: Алертинг**
- Yellow zone: Slack notification
- Orange zone: Email + Slack + создание Jira ticket
- Red zone: Critical alert + PagerDuty + SMS on-call инженеру

**Уровень 3: Автоматические действия**
- Auto-scaling: При Orange zone для CPU/Memory/HTTP Queue
- Auto-kill: Процессы с memory leaks при Red zone
- Auto-restart: Сервисов при критических проблемах
- Circuit breaker: Автоматическое включение при перегрузке

**Уровень 4: Превентивные меры**
- Capacity planning на основе трендов
- Предсказание насыщенности (ML models)
- Регулярный review и adjustment пороговых значений

---

## Заключение

Внедрение комплексной системы мониторинга с правильно настроенными метриками и показателями насыщенности позволит компании "Александрит":

1. **Предотвращать проблемы до их возникновения** - через мониторинг насыщенности
2. **Быстро реагировать на инциденты** - через алертинг и автоматизацию
3. **Принимать обоснованные решения** - через исторические данные и тренды
4. **Масштабироваться эффективно** - через понимание узких мест

Приоритизация началась с RED метрик для сервисов и USE метрик для инфраструктуры, что даст максимальную ценность на начальном этапе. Дополнительные метрики можно добавлять постепенно по мере созревания системы мониторинга.
